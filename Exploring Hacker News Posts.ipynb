{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News Submission Analysis\n",
    "\n",
    "Hacker News is a site started by Y combinator where users submit posts that are voted on and discussed. The site is popular among those in the tech industry as well as startup circles, and consequently, the links that top the Hacker News listings get a lot of visitors. \n",
    "\n",
    "The original data has been filtered from 300,000 rows to a smaller dataset of 20,000 rows by\n",
    "1. Removing all submissions that do not have a comment\n",
    "2. Creating a random sample of the remaining submissions\n",
    "\n",
    "We're interested in posts that begin with either `Ask HN` or `Show HN`. Users submit `Ask HN` posts to ask a certain question, and `Show HN` posts to showcase a product, project or anything interesting.\n",
    "\n",
    "Our objective is to study the sample, and determine\n",
    "1. Which of the 2 types of the posts receive more comments on average\n",
    "2. Do posts created at certain times receive more comments on average\n",
    "\n",
    "# Data Import\n",
    "\n",
    "The source data can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts). We will first read the file, and import it as a list of lists. We'll also separate the header from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "import datetime as dt\n",
    "\n",
    "opened_file = open('/Users/shubzroy/Documents/GitHub/Analytics/Datasets/HN_posts_year_to_Sep_26_2016.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "hn_header = hn[0]\n",
    "hn = hn[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24'],\n",
       " ['12578997',\n",
       "  'What if we just printed a flatscreen television on the side of our boxes?',\n",
       "  'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43',\n",
       "  '1',\n",
       "  '0',\n",
       "  'pavel_lishin',\n",
       "  '9/26/2016 3:19'],\n",
       " ['12578989',\n",
       "  'algorithmic music',\n",
       "  'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext',\n",
       "  '1',\n",
       "  '0',\n",
       "  'poindontcare',\n",
       "  '9/26/2016 3:16'],\n",
       " ['12578979',\n",
       "  'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake',\n",
       "  'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94',\n",
       "  '1',\n",
       "  '0',\n",
       "  'markgainor1',\n",
       "  '9/26/2016 3:14']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Data\n",
    "\n",
    "We will have to filter the data to separate out the `Ask HN`, `Show HN`, and all other posts based on the title. The title starts with either or none of the two labels, and based on this we'll create 3 separate lists.\n",
    "\n",
    "Note for DQ: The dataset originally has ~300,000 records, and filters down to ~20,000 records after this step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "10158\n",
      "273822\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for post in hn:\n",
    "    title = post[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(post)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(post)\n",
    "    else:\n",
    "        other_posts.append(post)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12578908',\n",
       "  'Ask HN: What TLD do you use for local development?',\n",
       "  '',\n",
       "  '4',\n",
       "  '7',\n",
       "  'Sevrene',\n",
       "  '9/26/2016 2:53'],\n",
       " ['12578522',\n",
       "  'Ask HN: How do you pass on your work when you die?',\n",
       "  '',\n",
       "  '6',\n",
       "  '3',\n",
       "  'PascLeRasc',\n",
       "  '9/26/2016 1:17'],\n",
       " ['12577908',\n",
       "  'Ask HN: How a DNS problem can be limited to a geographic region?',\n",
       "  '',\n",
       "  '1',\n",
       "  '0',\n",
       "  'kuon',\n",
       "  '9/25/2016 22:57'],\n",
       " ['12577870',\n",
       "  'Ask HN: Why join a fund when you can be an angel?',\n",
       "  '',\n",
       "  '1',\n",
       "  '3',\n",
       "  'anthony_james',\n",
       "  '9/25/2016 22:48'],\n",
       " ['12577647',\n",
       "  'Ask HN: Someone uses stock trading as passive income?',\n",
       "  '',\n",
       "  '5',\n",
       "  '2',\n",
       "  '00taffe',\n",
       "  '9/25/2016 21:50']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_posts[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12578335',\n",
       "  'Show HN: Finding puns computationally',\n",
       "  'http://puns.samueltaylor.org/',\n",
       "  '2',\n",
       "  '0',\n",
       "  'saamm',\n",
       "  '9/26/2016 0:36'],\n",
       " ['12578182',\n",
       "  'Show HN: A simple library for complicated animations',\n",
       "  'https://christinecha.github.io/choreographer-js/',\n",
       "  '1',\n",
       "  '0',\n",
       "  'christinecha',\n",
       "  '9/26/2016 0:01'],\n",
       " ['12578098',\n",
       "  'Show HN: WebGL visualization of DNA sequences',\n",
       "  'http://grondilu.github.io/dna.html',\n",
       "  '1',\n",
       "  '0',\n",
       "  'grondilu',\n",
       "  '9/25/2016 23:44'],\n",
       " ['12577991',\n",
       "  'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules',\n",
       "  'https://github.com/jakebian/zeal',\n",
       "  '2',\n",
       "  '0',\n",
       "  'dbranes',\n",
       "  '9/25/2016 23:17'],\n",
       " ['12577142',\n",
       "  'Show HN: Jumble  Essays on the go #PaulInYourPocket',\n",
       "  'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8',\n",
       "  '1',\n",
       "  '1',\n",
       "  'ryderj',\n",
       "  '9/25/2016 20:06']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_posts[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "Let's look at which of the post type received more comments on average. We'll start with the `Ask HN` posts first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13569.42857142857\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    num_comments = int(post[4])\n",
    "    total_ask_comments += num_comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(post)\n",
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "\n",
    "for post in show_posts:\n",
    "    num_comments = int(post[4])\n",
    "    total_show_comments += num_comments\n",
    "\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that average number of comments are significantly higher for the `Ask HN` posts than for the `Show HN` posts. On average, `Ask HN` posts receive over 2700 times more comments than `Show HN` posts.\n",
    "\n",
    "Since we see that the `Ask HN` posts recevied more comments, we'll use this dataset to see if there were posts created at specific times which received more comments. We'll iterate through the `Ask HN` posts to get to total number of comments received each hour, and the number of posts for each hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    created_at = post[6]\n",
    "    num_comments = int(post[4])\n",
    "    result_list.append([created_at, num_comments])\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    dt_string = row[0]\n",
    "    num_comments = row[1]\n",
    "    dt_time = dt.datetime.strptime(dt_string, \"%m/%d/%Y %H:%M\")\n",
    "    dt_hour = dt.datetime.strftime(dt_time, \"%H\")\n",
    "    if dt_hour not in counts_by_hour:\n",
    "        counts_by_hour[dt_hour] = 1 \n",
    "        comments_by_hour[dt_hour] =  num_comments\n",
    "    else:\n",
    "        counts_by_hour[dt_hour] += 1 \n",
    "        comments_by_hour[dt_hour] +=  num_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the above to calculate the average number of comments per post for each hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['02', 11.14], ['01', 7.41], ['22', 8.8], ['21', 8.69], ['19', 7.16], ['17', 9.45], ['15', 28.68], ['14', 9.69], ['13', 16.32], ['11', 8.96], ['10', 10.68], ['09', 6.65], ['07', 7.01], ['03', 7.95], ['23', 6.7], ['20', 8.75], ['16', 7.71], ['08', 9.19], ['00', 7.56], ['18', 7.94], ['12', 12.38], ['04', 9.71], ['06', 6.78], ['05', 8.79]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hours in comments_by_hour:\n",
    "    avg_by_hour.append([hours, round(comments_by_hour[hours]/counts_by_hour[hours],2)])\n",
    "\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the list of lists in order of descending average number of comments per hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 28.68 average comments per post\n",
      "13:00: 16.32 average comments per post\n",
      "12:00: 12.38 average comments per post\n",
      "02:00: 11.14 average comments per post\n",
      "10:00: 10.68 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for hours in avg_by_hour:\n",
    "    swap_avg_by_hour.append([hours[1],hours[0]])\n",
    "    \n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "for ranking in sorted_swap[0:5]:\n",
    "    template = \"{0}: {1:.2f} average comments per post\"\n",
    "    rank_time = dt.datetime.strptime(ranking[1], \"%H\")\n",
    "    time_hr = dt.datetime.strftime(rank_time, \"%H:%M\")\n",
    "    print(template.format(time_hr, ranking[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the above ranking, you'd want to create a post at 3pm EST (2pm CST) for the highest probability for receiving comments. Seeing the top 5 hours, if a range is required, you'd have a high probability of comments 12-3pm EST (11am-2pm CST). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
